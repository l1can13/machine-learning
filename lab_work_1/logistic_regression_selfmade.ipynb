{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-24T12:33:09.345931Z",
     "start_time": "2023-10-24T12:33:08.704520400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class SelfmadeLogisticRegression:  # Определяем класс SelfmadeLogisticRegression.\n",
    "    def __init__(self, learning_rate=0.1, n_iterations=5000,\n",
    "                 reg_strength=1):  # Конструктор класса с параметрами по умолчанию.\n",
    "        self.learning_rate = learning_rate  # Устанавливаем скорость обучения.\n",
    "        self.n_iterations = n_iterations  # Устанавливаем количество итераций обучения.\n",
    "        self.reg_strength = reg_strength  # Устанавливаем коэффициент регуляризации.\n",
    "        self.models_weights = {}  # Инициализируем пустой словарь для хранения весов моделей.\n",
    "        self.models_biases = {}  # Инициализируем пустой словарь для хранения смещений моделей.\n",
    "\n",
    "    def sigmoid(self, z):  # Определяем метод для расчета сигмоидной функции.\n",
    "        return 1 / (1 + np.exp(-z))  # Возвращаем значение сигмоидной функции.\n",
    "\n",
    "    def softmax(self, z):  # Определяем метод для расчета softmax функции.\n",
    "        exp_z = np.exp(z - np.max(z, axis=1,\n",
    "                                  keepdims=True))  # Вычисляем экспоненты и вычитаем максимальное значение для стабильности.\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)  # Возвращаем нормализованные вероятности по классам.\n",
    "\n",
    "    def log_loss(self, y, predictions):  # Определяем метод для расчета функции потерь log loss.\n",
    "        epsilon = 1e-15  # Очень маленькое значение для стабильности.\n",
    "        predictions = np.clip(predictions, epsilon,\n",
    "                              1 - epsilon)  # Обрезаем предсказания для избежания выхода за границы логарифма.\n",
    "        loss = - np.sum(y * np.log(predictions))  # Рассчитываем log loss.\n",
    "        return np.mean(loss)  # Возвращаем среднее значение log loss по всем примерам.\n",
    "\n",
    "    def fit(self, X, y):  # Определяем метод для обучения модели.\n",
    "        unique_classes = np.unique(y)  # Получаем уникальные классы в целевой переменной.\n",
    "        n_classes = len(unique_classes)  # Получаем количество классов.\n",
    "        n_samples, n_features = X.shape  # Получаем количество примеров и признаков.\n",
    "\n",
    "        for i, cls in enumerate(unique_classes):  # Итерируемся по уникальным классам.\n",
    "            binary_y = (y == cls).astype(int)  # Преобразуем многоклассовую задачу в бинарную для текущего класса.\n",
    "            weights, bias = self.train_model(X, binary_y)  # Обучаем модель для бинарной классификации.\n",
    "            self.models_weights[i] = weights  # Сохраняем веса модели для текущего класса.\n",
    "            self.models_biases[i] = bias  # Сохраняем смещение модели для текущего класса.\n",
    "\n",
    "    def train_model(self, X, y):  # Определяем метод для обучения бинарной модели.\n",
    "        n_samples, n_features = X.shape  # Получаем количество примеров и признаков.\n",
    "        weights = np.zeros(n_features)  # Инициализируем веса нулями.\n",
    "        bias = 0  # Инициализируем смещение нулем.\n",
    "\n",
    "        for _ in range(self.n_iterations):  # Итерируемся по заданному числу итераций.\n",
    "            model = np.dot(X, weights) + bias  # Вычисляем модель.\n",
    "            predictions = self.sigmoid(model)  # Применяем сигмоиду к модели для получения предсказаний.\n",
    "\n",
    "            dw = (1 / n_samples) * (np.dot(X.T, (\n",
    "                    predictions - y)) + 2 * self.reg_strength * weights)  # Рассчитываем градиент по весам.\n",
    "            db = (1 / n_samples) * np.sum(predictions - y)  # Рассчитываем градиент по смещению.\n",
    "\n",
    "            weights -= self.learning_rate * dw  # Обновляем веса.\n",
    "            bias -= self.learning_rate * db  # Обновляем смещение.\n",
    "\n",
    "        return weights, bias  # Возвращаем обученные веса и смещение.\n",
    "\n",
    "    def predict(self, X):  # Определяем метод для предсказания классов.\n",
    "        predictions = np.zeros((X.shape[0], len(self.models_weights)))  # Инициализируем массив для предсказаний.\n",
    "\n",
    "        for i, (weights, bias) in enumerate(zip(self.models_weights.values(),\n",
    "                                                self.models_biases.values())):  # Итерируемся по сохраненным весам и смещениям.\n",
    "            model_predictions = np.dot(X, weights) + bias  # Вычисляем предсказания для текущей модели.\n",
    "            predictions[:, i] = model_predictions  # Сохраняем предсказания в массив.\n",
    "\n",
    "        return np.argmax(self.softmax(predictions), axis=1)  # Возвращаем индексы классов с наибольшей вероятностью."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T12:33:09.360372100Z",
     "start_time": "2023-10-24T12:33:09.354032900Z"
    }
   },
   "id": "663ee7d4531ae7f6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_data(file_path):  # Определяем функцию для загрузки данных.\n",
    "    with open(file_path, 'r') as file:  # Открываем файл для чтения.\n",
    "        lines = file.readlines()  # Считываем все строки из файла.\n",
    "\n",
    "    header = lines[0].strip().split(',')  # Получаем заголовок данных.\n",
    "    data_lines = [line.strip().split(',') for line in lines[1:]]  # Преобразуем строки данных в список списков.\n",
    "\n",
    "    train_features = [list(map(float, line[:-2])) for line in data_lines if\n",
    "                      line[-1] == 'train']  # Извлекаем признаки для тренировочных данных.\n",
    "    train_labels = [int(line[-2]) for line in data_lines if\n",
    "                    line[-1] == 'train']  # Извлекаем метки классов для тренировочных данных.\n",
    "\n",
    "    test_features = [list(map(float, line[:-2])) for line in data_lines if\n",
    "                     line[-1] == 'test']  # Извлекаем признаки для тестовых данных.\n",
    "    # Добавляем лейбл -1 к тестовым данным\n",
    "    test_labels = [-1] * len(test_features)  # Создаем список из -1 для меток тестовых данных.\n",
    "\n",
    "    return (\n",
    "        np.array(train_features),  # Возвращаем массив тренировочных признаков.\n",
    "        np.array(train_labels),  # Возвращаем массив меток тренировочных данных.\n",
    "        np.array(test_features),  # Возвращаем массив тестовых признаков.\n",
    "        np.array(test_labels)  # Возвращаем массив меток тестовых данных.\n",
    "    )\n",
    "\n",
    "\n",
    "def save_predictions(predictions, file_path):  # Определяем функцию для сохранения предсказаний.\n",
    "    np.savetxt(file_path, predictions, fmt='%d',\n",
    "               delimiter=',')  # Сохраняем предсказания в файл с форматом '%d' и разделителем ','."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T12:33:09.385899600Z",
     "start_time": "2023-10-24T12:33:09.363382Z"
    }
   },
   "id": "247cbc10d43b82b6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, tt_test = load_data('input.txt')  # Загружаем данные из файла 'input.txt'."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T12:33:09.386900800Z",
     "start_time": "2023-10-24T12:33:09.371890200Z"
    }
   },
   "id": "395789f2cc79098e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model = SelfmadeLogisticRegression(n_iterations=5000)  # Создаем экземпляр модели с указанными параметрами.\n",
    "model.fit(x_train, y_train)  # Обучаем модель на тренировочных данных."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T12:33:09.870440100Z",
     "start_time": "2023-10-24T12:33:09.386900800Z"
    }
   },
   "id": "f667d952c4a783d7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "selfmade_predictions = model.predict(x_test)  # Предсказываем классы для тестовых данных."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T12:33:09.877189600Z",
     "start_time": "2023-10-24T12:33:09.871449Z"
    }
   },
   "id": "3584032e4f19294d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "save_predictions(selfmade_predictions, 'output.txt')  # Сохраняем предсказания в файл 'output.txt'."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T12:33:09.884914300Z",
     "start_time": "2023-10-24T12:33:09.875183600Z"
    }
   },
   "id": "a566e15df2a4332b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
