{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-02T09:47:27.087329700Z",
     "start_time": "2023-10-02T09:47:27.069948100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.97258568  0.33000871]\n",
      " [ 1.97754947  0.29882787]\n",
      " [ 0.66403114 -0.74770492]\n",
      " [ 1.87515029  0.69556553]\n",
      " [ 1.18067338  1.61431421]]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "x_train = np.load('datasets/dataset2/x_train.npy')\n",
    "y_train = np.load('datasets/dataset2/y_train.npy')\n",
    "\n",
    "x_test = np.load('datasets/dataset2/x_test.npy')\n",
    "y_test = np.load('datasets/dataset2/y_test.npy')\n",
    "\n",
    "print(x_train[:5])\n",
    "print(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T09:47:27.087329700Z",
     "start_time": "2023-10-02T09:47:27.073466800Z"
    }
   },
   "id": "663ee7d4531ae7f6"
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "class SelfmadeLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000, reg_strength=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.reg_strength = reg_strength\n",
    "        self.models = {}  # Словарь моделей для каждого класса\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def log_loss(self, y, predictions):\n",
    "        epsilon = 1e-15\n",
    "        predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "        loss = - (y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        unique_classes = np.unique(y)\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            binary_y = (y == cls).astype(int)  # Преобразуем к бинарной классификации\n",
    "            model = self.train_binary_model(X, binary_y)\n",
    "            self.models[cls] = model\n",
    "\n",
    "    def train_binary_model(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        weights = np.zeros(n_features)\n",
    "        bias = 0\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            model = np.dot(X, weights) + bias\n",
    "            predictions = self.sigmoid(model)\n",
    "\n",
    "            dw = (1/n_samples) * (np.dot(X.T, (predictions - y)) + self.reg_strength * weights)\n",
    "            db = (1/n_samples) * np.sum(predictions - y)\n",
    "\n",
    "            weights -= self.learning_rate * dw\n",
    "            bias -= self.learning_rate * db\n",
    "\n",
    "        return weights, bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((X.shape[0], len(self.models)))\n",
    "\n",
    "        for cls, model in self.models.items():\n",
    "            weights, bias = model\n",
    "            model_predictions = np.dot(X, weights) + bias\n",
    "            predictions[:, cls] = self.sigmoid(model_predictions)\n",
    "\n",
    "        # Выбираем класс с наибольшей вероятностью\n",
    "        return np.argmax(predictions, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T09:47:27.095350500Z",
     "start_time": "2023-10-02T09:47:27.089316700Z"
    }
   },
   "id": "247cbc10d43b82b6"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели: 66.00%\n",
      "[0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Инициализация модели\n",
    "model = LogisticRegression(\n",
    "    solver='liblinear',\n",
    "    C=100.0,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Точность модели: {accuracy * 100:.2f}%')\n",
    "print(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T09:47:27.119953500Z",
     "start_time": "2023-10-02T09:47:27.095350500Z"
    }
   },
   "id": "395789f2cc79098e"
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[170], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m selfmade_model \u001B[38;5;241m=\u001B[39m SelfmadeLogisticRegression()\n\u001B[0;32m      3\u001B[0m selfmade_model\u001B[38;5;241m.\u001B[39mfit(x_train, y_train)\n\u001B[1;32m----> 4\u001B[0m selfmade_predictions \u001B[38;5;241m=\u001B[39m \u001B[43mselfmade_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(selfmade_predictions)\n",
      "Cell \u001B[1;32mIn[168], line 48\u001B[0m, in \u001B[0;36mSelfmadeLogisticRegression.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     46\u001B[0m     weights, bias \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m     47\u001B[0m     model_predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(X, weights) \u001B[38;5;241m+\u001B[39m bias\n\u001B[1;32m---> 48\u001B[0m     \u001B[43mpredictions\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigmoid(model_predictions)\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# Выбираем класс с наибольшей вероятностью\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39margmax(predictions, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mIndexError\u001B[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# Используем класс\n",
    "selfmade_model = SelfmadeLogisticRegression()\n",
    "selfmade_model.fit(x_train, y_train)\n",
    "selfmade_predictions = selfmade_model.predict(x_test)\n",
    "\n",
    "print(selfmade_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T09:47:27.202984200Z",
     "start_time": "2023-10-02T09:47:27.109413500Z"
    }
   },
   "id": "732605c9dcb4eba3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Сравнение результатов\n",
    "selfmade_accuracy = accuracy_score(y_test, selfmade_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-02T09:47:27.200983400Z"
    }
   },
   "id": "41c7baa4188a193a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Точность самописной модели: {selfmade_accuracy * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-02T09:47:27.202984200Z"
    }
   },
   "id": "85aa00af284a1ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
